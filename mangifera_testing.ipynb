{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMm9iND1CcNRU4iBbcErge7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Importing libraries\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","import cv2\n","import os\n","\n","# Loading data\n","data_dir = '/content/Mangifera'\n","image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n","imgpath_zero = image_paths[0]\n","names = [f.split('-')[0].split('/')[-1] for f in image_paths]\n","name_list = list(set(names))\n","\n","labels = [name_list.index(name) for name in names]\n","\n","# Preprocessing data\n","scaler = StandardScaler()\n","X = []\n","y = []\n","for i, path in enumerate(image_paths):\n","    img = cv2.imread(path)\n","    img = cv2.resize(img, (224, 224))\n","    img = img / 255.0\n","    X.append(img)\n","    y.append(labels[i])\n","\n","\n","X = np.array(X)\n","y = np.array(y)"],"metadata":{"id":"yaE-aQHZxJyi","executionInfo":{"status":"error","timestamp":1753186266472,"user_tz":-480,"elapsed":11813,"user":{"displayName":"TAM Work","userId":"15604394458332215355"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"c8cbca19-138e-4f16-a77e-1558bb3dce78"},"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/Mangifera'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-145846804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Loading data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Mangifera'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mimgpath_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Mangifera'"]}]},{"cell_type":"code","source":["# Data preprocessing\n","X = X.reshape(-1, 224, 224, 3)\n","X = X.astype('float32')\n","\n","# Splitting data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"MLzDGI20SYAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data augmentation\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","datagen.fit(X_train)"],"metadata":{"id":"ir2kQCPJSdEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model definition\n","model = keras.Sequential([\n","    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    keras.layers.MaxPooling2D((2, 2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dropout(0.2),\n","    keras.layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XWqLH2XSfr-","executionInfo":{"status":"ok","timestamp":1747972659315,"user_tz":-480,"elapsed":412,"user":{"displayName":"TAM Work","userId":"15604394458332215355"}},"outputId":"dd528130-9789-4323-d91d-3400d3b1e421"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["# Model training\n","history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n","                    epochs=10,\n","                    validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdOLFLmASi-u","executionInfo":{"status":"ok","timestamp":1747975028545,"user_tz":-480,"elapsed":2361826,"user":{"displayName":"TAM Work","userId":"15604394458332215355"}},"outputId":"32b9355f-532a-4d00-e7e1-1c12873d2d5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 4s/step - accuracy: 0.2068 - loss: 1.8803 - val_accuracy: 0.2420 - val_loss: 3.5430\n","Epoch 2/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 4s/step - accuracy: 0.2371 - loss: 1.7151 - val_accuracy: 0.2463 - val_loss: 4.7347\n","Epoch 3/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 4s/step - accuracy: 0.2323 - loss: 1.7132 - val_accuracy: 0.2420 - val_loss: 5.8239\n","Epoch 4/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 4s/step - accuracy: 0.2384 - loss: 1.6728 - val_accuracy: 0.2420 - val_loss: 5.9197\n","Epoch 5/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 4s/step - accuracy: 0.2317 - loss: 1.7353 - val_accuracy: 0.2355 - val_loss: 5.9903\n","Epoch 6/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 4s/step - accuracy: 0.2484 - loss: 1.7121 - val_accuracy: 0.2355 - val_loss: 6.3799\n","Epoch 7/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.2603 - loss: 1.6739 - val_accuracy: 0.2355 - val_loss: 5.3089\n","Epoch 8/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 4s/step - accuracy: 0.2269 - loss: 1.7059 - val_accuracy: 0.2355 - val_loss: 6.0925\n","Epoch 9/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 4s/step - accuracy: 0.2348 - loss: 1.6786 - val_accuracy: 0.2355 - val_loss: 7.1628\n","Epoch 10/10\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 4s/step - accuracy: 0.2513 - loss: 1.6879 - val_accuracy: 0.2355 - val_loss: 6.4530\n"]}]},{"cell_type":"code","source":["print(history.history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsRih35ZcWwj","executionInfo":{"status":"ok","timestamp":1747975373309,"user_tz":-480,"elapsed":20,"user":{"displayName":"TAM Work","userId":"15604394458332215355"}},"outputId":"c473165e-7594-4c2d-c004-fd50a728472f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'accuracy': [0.2219839096069336, 0.22734583914279938, 0.2428954392671585, 0.22412869334220886, 0.22895441949367523, 0.2402144819498062, 0.2402144819498062, 0.2252010703086853, 0.23592492938041687, 0.25308310985565186], 'loss': [1.7823289632797241, 1.7033798694610596, 1.7015650272369385, 1.704797387123108, 1.6962409019470215, 1.6968892812728882, 1.691412329673767, 1.688745141029358, 1.6904929876327515, 1.6798045635223389], 'val_accuracy': [0.2419700175523758, 0.24625267088413239, 0.2419700175523758, 0.2419700175523758, 0.2355460375547409, 0.2355460375547409, 0.2355460375547409, 0.2355460375547409, 0.2355460375547409, 0.2355460375547409], 'val_loss': [3.5429887771606445, 4.734655380249023, 5.823859214782715, 5.919719219207764, 5.9902663230896, 6.37990665435791, 5.308897972106934, 6.092505931854248, 7.162765026092529, 6.452974796295166]}\n"]}]}]}
