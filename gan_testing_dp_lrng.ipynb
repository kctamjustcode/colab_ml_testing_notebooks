{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XoukozQJubx"
      },
      "outputs": [],
      "source": [
        "# lr, size, range, algo\n",
        "\n",
        "import torch, random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 6)\n",
        "        self.fc2 = nn.Linear(6, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "class SeqModel(nn.Module):\n",
        "    def __init__(self, input_features, output_features, hidden_units=8):\n",
        "      super(SeqModel, self).__init__()\n",
        "      self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(input_features, hidden_units),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(hidden_units, output_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.linear_layer_stack(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "#y_train = torch.tensor([[0.0], [1.0], [1.0], [0.0]])\n",
        "\n",
        "X_trn = [[random.uniform(0, 1), random.uniform(0, 1)] for _ in range(3000)]\n",
        "y_trn = [[round(X_trn[i][0])^round(X_trn[i][1])] for i in range(3000)]\n",
        "X_train = torch.tensor(X_trn, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_trn, dtype=torch.float32)\n",
        "print(X_train[:10], y_train[:10])\n",
        "\n",
        "# Instantiate the Model, Define Loss Function and Optimizer\n",
        "model = SimpleNN()\n",
        "#criterion = nn.MSELoss()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
        "\n",
        "for epoch in range(500):\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    #print(outputs)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/500], Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "    predictions = model(test_data)\n",
        "    print(f'Predictions:\\n{predictions}')\n",
        "    # results very sensitive to random initial parameters\n",
        "\n",
        "\n",
        "# Instantiate the Model, Define Loss Function and Optimizer\n",
        "model_seq = SeqModel(2,1)\n",
        "#criterion_seq = nn.MSELoss()\n",
        "criterion_seq = nn.BCEWithLogitsLoss()\n",
        "optimizer_seq = optim.Adam(model_seq.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(500):\n",
        "    model_seq.train()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs_seq = model_seq(X_train)\n",
        "    loss_seq = criterion_seq(outputs_seq, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer_seq.zero_grad()\n",
        "    loss_seq.backward()\n",
        "    optimizer_seq.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/500], Loss: {loss_seq.item():.4f}')\n",
        "\n",
        "model_seq.eval()\n",
        "with torch.no_grad():\n",
        "    test_data_seq = torch.tensor([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "    predictions_seq = model_seq(test_data_seq)\n",
        "    print(f'Predictions:\\n{predictions_seq}')\n",
        "    # results very sensitive to random initial parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFsRU-R95p3d",
        "outputId": "2d07fad3-cecc-4680-db8f-0af0eedd6a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2004, 0.9548],\n",
            "        [0.2228, 0.6909],\n",
            "        [0.0244, 0.2827],\n",
            "        [0.8088, 0.9146],\n",
            "        [0.1571, 0.5011],\n",
            "        [0.8398, 0.3143],\n",
            "        [0.5947, 0.1814],\n",
            "        [0.3845, 0.4351],\n",
            "        [0.7878, 0.8607],\n",
            "        [0.3123, 0.9838]]) tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]])\n",
            "Epoch [100/500], Loss: 0.6691\n",
            "Epoch [200/500], Loss: 0.5865\n",
            "Epoch [300/500], Loss: 0.5519\n",
            "Epoch [400/500], Loss: 0.5403\n",
            "Epoch [500/500], Loss: 0.5344\n",
            "Predictions:\n",
            "tensor([[7.7946e-14],\n",
            "        [9.5812e-01],\n",
            "        [9.9998e-01],\n",
            "        [1.4803e-13]])\n",
            "Epoch [100/500], Loss: 0.5811\n",
            "Epoch [200/500], Loss: 0.3990\n",
            "Epoch [300/500], Loss: 0.3467\n",
            "Epoch [400/500], Loss: 0.3456\n",
            "Epoch [500/500], Loss: 0.3456\n",
            "Predictions:\n",
            "tensor([[-3.7573],\n",
            "        [ 6.9890],\n",
            "        [ 8.3800],\n",
            "        [-3.5726]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(torch.tensor([[0.51,0.01]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QNSvJB3f9Ry",
        "outputId": "49679c53-21c6-4469-fa8e-353ed79cb0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9962]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.noise_dim = noise_dim\n",
        "        self.fc1 = nn.Linear(noise_dim, 4)\n",
        "        self.fc2 = nn.Linear(4, 4)\n",
        "        self.fc3 = nn.Linear(4, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.fc1 = nn.Linear(2, 6)\n",
        "      self.fc2 = nn.Linear(6, 4)\n",
        "      self.fc3 = nn.Linear(4, 1)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.relu(self.fc1(x))\n",
        "      x = self.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "PdSkswbAJ2sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 4\n",
        "\n",
        "generator = Generator(NOISE_DIM)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = generator.to(device)\n",
        "discriminator = discriminator.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.MSELoss()\n",
        "\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=0.02, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=0.02, betas=(0.5, 0.999))\n",
        "\n",
        "NUM_EPOCHS = 200\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SIZE = 10000\n",
        "\n",
        "x_trn = [[random.uniform(0, 1), random.uniform(0, 1)] for _ in range(SAMPLE_SIZE)]\n",
        "y_trn = [round(x_trn[i][0])^round(x_trn[i][1]) for i in range(SAMPLE_SIZE)]\n",
        "train_dataset =  [[x_trn[i][0],x_trn[i][1],y_trn[i]] for i in range(SAMPLE_SIZE)]\n",
        "train_dataset = torch.tensor(train_dataset)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "DEwWbkMkKM3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# malfunctioning, attempting ideas: discriminator~basic dnn with gan attacked\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for test in train_loader:\n",
        "\n",
        "      real_images = test[:,:2]\n",
        "      #real_images = real_images.to(device)\n",
        "\n",
        "      discriminator_optimizer.zero_grad()\n",
        "      #real_labels = torch.ones(real_images.size(0), 1, device=device)\n",
        "      real_labels = test[:,2:]\n",
        "      #print(real_labels)\n",
        "      real_outputs = discriminator(real_images)\n",
        "      #print(real_outputs)\n",
        "      #print(real_labels)\n",
        "      real_loss = criterion(real_outputs, real_labels)\n",
        "      #real_loss.backward()\n",
        "\n",
        "      noise = torch.randn(real_images.size(0), NOISE_DIM, device=device)\n",
        "      #print(noise)\n",
        "      fake_images = generator(noise)\n",
        "      real_list = real_labels.tolist()\n",
        "      fake_labels = torch.tensor([[round(real_list[i][0])^1] for i in range(len(real_list))], dtype=torch.float32)\n",
        "      fake_outputs = discriminator(fake_images.detach())\n",
        "      #print(fake_labels)\n",
        "\n",
        "      #fo_tl = fake_outputs.tolist()\n",
        "      #fake_outputs_labels = torch.tensor([[round(fo_tl[i][0])] for i in range(len(fo_tl))], dtype=torch.float32)\n",
        "      fake_outputs_labels = torch.zeros(real_images.size(0), 1, device=device)\n",
        "      fake_loss = criterion(fake_outputs, fake_outputs_labels)\n",
        "      #print(fake_outputs_labels)\n",
        "      #fake_loss.backward()\n",
        "      d_loss = (real_loss + fake_loss) / 2\n",
        "      d_loss.backward()\n",
        "      discriminator_optimizer.step()\n",
        "\n",
        "      generator_optimizer.zero_grad()\n",
        "      #fake_labels = real_labels\n",
        "      gen_images = generator(noise)\n",
        "      gen_outputs = discriminator(gen_images)\n",
        "      gen_loss = criterion(gen_outputs, real_labels)\n",
        "      gen_loss.backward()\n",
        "      generator_optimizer.step()\n",
        "\n",
        "    if epoch == 0 or epoch == NUM_EPOCHS-1:\n",
        "      print(f'Epoch [{epoch+1}/{NUM_EPOCHS}]'#, Step [{epoch+1}/{len(train_loader)}], '\n",
        "            f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "            f'Generator Loss: {gen_loss.item():.4f}')\n",
        "    elif epoch % 10 == 0 and epoch != 0:\n",
        "      print(f'Epoch [{epoch}/{NUM_EPOCHS}]'#, Step [{epoch+1}/{len(train_loader)}], '\n",
        "            f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "            f'Generator Loss: {gen_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0cFvvJuLX24",
        "outputId": "92df85a8-ec18-4930-acb8-51265649a5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200]Discriminator Loss: 0.4804, Generator Loss: 1.0834\n",
            "Epoch [10/200]Discriminator Loss: 0.3128, Generator Loss: 1.0987\n",
            "Epoch [20/200]Discriminator Loss: 0.3717, Generator Loss: 1.0267\n",
            "Epoch [30/200]Discriminator Loss: 0.4158, Generator Loss: 1.2639\n",
            "Epoch [40/200]Discriminator Loss: 0.3635, Generator Loss: 1.0886\n",
            "Epoch [50/200]Discriminator Loss: 0.2084, Generator Loss: 0.6750\n",
            "Epoch [60/200]Discriminator Loss: 0.5735, Generator Loss: 1.2487\n",
            "Epoch [70/200]Discriminator Loss: 0.3346, Generator Loss: 1.1075\n",
            "Epoch [80/200]Discriminator Loss: 0.2101, Generator Loss: 0.8472\n",
            "Epoch [90/200]Discriminator Loss: 0.2119, Generator Loss: 0.6646\n",
            "Epoch [100/200]Discriminator Loss: 0.2617, Generator Loss: 1.0231\n",
            "Epoch [110/200]Discriminator Loss: 0.0063, Generator Loss: 2.3623\n",
            "Epoch [120/200]Discriminator Loss: 0.0228, Generator Loss: 3.7128\n",
            "Epoch [130/200]Discriminator Loss: 0.0008, Generator Loss: 2.4217\n",
            "Epoch [140/200]Discriminator Loss: 0.0010, Generator Loss: 1.7247\n",
            "Epoch [150/200]Discriminator Loss: 0.0381, Generator Loss: 3.6341\n",
            "Epoch [160/200]Discriminator Loss: 0.0004, Generator Loss: 3.7677\n",
            "Epoch [170/200]Discriminator Loss: 0.1030, Generator Loss: 3.9025\n",
            "Epoch [180/200]Discriminator Loss: 0.0057, Generator Loss: 4.4652\n",
            "Epoch [190/200]Discriminator Loss: 0.0032, Generator Loss: 3.0430\n",
            "Epoch [200/200]Discriminator Loss: 0.0001, Generator Loss: 3.6179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, dis_model, epoch, noise):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = model(noise).cpu()\n",
        "        print(noise)\n",
        "        print(fake_images)\n",
        "        print(dis_model(fake_images))\n",
        "test_noise = torch.randn(4, NOISE_DIM, device=device)\n",
        "generate_and_save_images(generator, discriminator, NUM_EPOCHS, test_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPQzCRgoRh--",
        "outputId": "3439d488-8221-4675-fc04-36bc9a996182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6106,  0.0590, -0.5936, -1.9090],\n",
            "        [ 0.4375, -0.3661,  1.8641,  0.7534],\n",
            "        [-0.9431,  0.2412,  2.6971,  0.8192],\n",
            "        [-1.0979, -0.2990,  0.7012, -0.5589]])\n",
            "tensor([[-0.9844,  0.2292],\n",
            "        [-0.9844,  0.2292],\n",
            "        [-0.9844,  0.2292],\n",
            "        [-0.9844,  0.2292]])\n",
            "tensor([[-8.2689],\n",
            "        [-8.2689],\n",
            "        [-8.2689],\n",
            "        [-8.2689]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generator(torch.randn(1, NOISE_DIM, device=device)))\n",
        "print(discriminator(torch.tensor([[0.4901,0.6013]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20yZOFzrOED",
        "outputId": "88b19751-78dd-4087-8afe-3aa410f67b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9844,  0.2292]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[3.2466]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator_Thre(nn.Module):\n",
        "    def __init__(self, noise_dim):\n",
        "        super(Generator_Thre, self).__init__()\n",
        "        self.noise_dim = noise_dim\n",
        "        self.fc1 = nn.Linear(noise_dim, 2)\n",
        "        self.fc2 = nn.Linear(2, 4)\n",
        "        self.fc3 = nn.Linear(4, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator_Thre(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator_Thre, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 2)\n",
        "        self.fc2 = nn.Linear(2, 4)\n",
        "        self.fc3 = nn.Linear(4, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pHGscjMpKFMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 4\n",
        "\n",
        "generator_thre = Generator_Thre(NOISE_DIM)\n",
        "discriminator_thre = Discriminator_Thre()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator_thre = generator_thre.to(device)\n",
        "discriminator_thre = discriminator_thre.to(device)\n",
        "\n",
        "criterion_thre = nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.MSELoss()\n",
        "\n",
        "generator_thre_optimizer = optim.Adam(generator_thre.parameters(), lr=0.02, betas=(0.5, 0.999))\n",
        "discriminator_thre_optimizer = optim.Adam(discriminator_thre.parameters(), lr=0.02, betas=(0.5, 0.999))\n",
        "\n",
        "NUM_EPOCHS = 200\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SIZE = 10000\n",
        "\n",
        "x_trn = [[random.uniform(0, 1), random.uniform(0, 1)] for _ in range(SAMPLE_SIZE)]\n",
        "y_trn = [round(x_trn[i][0])^round(x_trn[i][1]) for i in range(SAMPLE_SIZE)]\n",
        "train_dataset =  [[x_trn[i][0],x_trn[i][1],y_trn[i]] for i in range(SAMPLE_SIZE)]\n",
        "train_dataset = torch.tensor(train_dataset)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "wCCxgx9MYdKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# theoretical gan: simply generate images and making the discriminator considering fake as real\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for test in train_loader:\n",
        "\n",
        "      real_signal = test[:,:2]\n",
        "      #real_images = real_images.to(device)\n",
        "\n",
        "      real_labels = torch.ones(real_signal.size(0), 1, device=device)\n",
        "      fake_labels = torch.zeros(real_signal.size(0), 1, device=device)\n",
        "\n",
        "      discriminator_thre_optimizer.zero_grad()\n",
        "\n",
        "      noise = torch.randn(real_signal.size(0), NOISE_DIM, device=device)\n",
        "\n",
        "      #real_labels = test[:,2:]\n",
        "      #print(real_labels)\n",
        "      real_outputs = discriminator_thre(real_signal)\n",
        "      real_loss = criterion_thre(real_outputs, real_labels)\n",
        "      #real_loss.backward()\n",
        "\n",
        "      #print(noise)\n",
        "      fake_signal = generator_thre(noise)\n",
        "      #real_list = real_labels.tolist()\n",
        "      #fake_labels = torch.tensor([[round(real_list[i][0])^1] for i in range(len(real_list))], dtype=torch.float32)\n",
        "      fake_outputs = discriminator_thre(fake_signal)\n",
        "      #print(fake_labels)\n",
        "\n",
        "      #fo_tl = fake_outputs.tolist()\n",
        "      #fake_outputs_labels = torch.tensor([[round(fo_tl[i][0])] for i in range(len(fo_tl))], dtype=torch.float32)\n",
        "      fake_loss = criterion_thre(fake_outputs, fake_labels)\n",
        "      #print(fake_outputs_labels)\n",
        "      #fake_loss.backward()\n",
        "      d_loss = (real_loss + fake_loss) / 2\n",
        "      d_loss.backward()\n",
        "      discriminator_thre_optimizer.step()\n",
        "\n",
        "      generator_thre_optimizer.zero_grad()\n",
        "      gen_signal = generator_thre(noise)\n",
        "      gen_outputs = discriminator_thre(gen_signal)\n",
        "      gen_loss = criterion_thre(gen_outputs, real_labels)\n",
        "      gen_loss.backward()\n",
        "      generator_thre_optimizer.step()\n",
        "\n",
        "    if epoch == 0 or epoch == NUM_EPOCHS-1:\n",
        "      print(f'Epoch [{epoch+1}/{NUM_EPOCHS}]'#, Step [{epoch+1}/{len(train_loader)}], '\n",
        "            f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "            f'Generator Loss: {gen_loss.item():.4f}')\n",
        "    elif epoch % 10 == 0 and epoch != 0:\n",
        "      print(f'Epoch [{epoch}/{NUM_EPOCHS}]'#, Step [{epoch+1}/{len(train_loader)}], '\n",
        "            f'Discriminator Loss: {d_loss.item():.4f}, '\n",
        "            f'Generator Loss: {gen_loss.item():.4f}')"
      ],
      "metadata": {
        "id": "HGWJ-MK2cINa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20d6684-2b3e-4c89-a748-7e203f422bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200]Discriminator Loss: 0.7069, Generator Loss: 0.8532\n",
            "Epoch [10/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [20/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [30/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [40/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [50/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [60/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [70/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [80/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [90/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [100/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [110/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [120/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [130/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [140/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [150/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [160/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [170/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [180/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [190/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n",
            "Epoch [200/200]Discriminator Loss: 0.6931, Generator Loss: 0.6931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, dis_model, epoch, noise):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = model(noise).cpu()\n",
        "        print(noise)\n",
        "        print(fake_images)\n",
        "        print(dis_model(fake_images))\n",
        "test_noise = torch.randn(4, NOISE_DIM, device=device)\n",
        "generate_and_save_images(generator_thre, discriminator_thre, NUM_EPOCHS, test_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FSKZtvB_GOM",
        "outputId": "4dc9440f-8146-4427-8f96-0a5446a9baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5961, -1.1986,  0.6461, -0.5769],\n",
            "        [-0.3068, -0.1979, -0.2972,  1.4376],\n",
            "        [-0.0141, -0.9585,  2.4865, -1.2544],\n",
            "        [-0.5225, -1.2762,  1.6555, -0.5477]])\n",
            "tensor([[-1.4096,  6.6109],\n",
            "        [ 0.4984,  0.4962],\n",
            "        [-2.7901,  5.9893],\n",
            "        [-1.5081,  3.9546]])\n",
            "tensor([[4.9303e-08],\n",
            "        [4.9303e-08],\n",
            "        [4.9303e-08],\n",
            "        [4.9303e-08]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(discriminator_thre(torch.tensor([[0.53,0.83]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJJ3nezdAqQo",
        "outputId": "88f445a7-814a-49fd-d452-d594c2fc1585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.9303e-08]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}